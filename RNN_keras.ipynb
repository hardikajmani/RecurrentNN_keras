{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_keras.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Ljp2Qpiv92aB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This a rnn with keras used for doing  sentiment analysis on tweets\n",
        "There is a dataset of 16000 lines and the task is to describe  each tweet as positive or negative.\n",
        "Although data is here and will also be uploaded with the code.\n",
        "Here's the link to download the dataset :\n",
        "https://github.com/crwong/cs224u-project/tree/master/data/sentiment"
      ]
    },
    {
      "metadata": {
        "id": "Wog1Y7cO9yE3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#importing the required libraries\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uINxl5Q3Am_w",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1482
        },
        "outputId": "42dc22a9-8c8c-46ea-eed3-2b1c449cf43d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528258883417,
          "user_tz": -330,
          "elapsed": 330852,
          "user": {
            "displayName": "Hardik Ajmani",
            "photoUrl": "//lh3.googleusercontent.com/-vIpwTK-rcVg/AAAAAAAAAAI/AAAAAAAAFT4/chdlQWDf_D4/s50-c-k-no/photo.jpg",
            "userId": "117937753219477580457"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install spacy\n",
        "!python -m spacy download en"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/31/e60f88751e48851b002f78a35221d12300783d5a43d4ef12fbf10cca96c3/spacy-2.0.11.tar.gz (17.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 17.6MB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.14.3)\n",
            "Collecting murmurhash<0.29,>=0.28 (from spacy)\n",
            "  Downloading https://files.pythonhosted.org/packages/5e/31/c8c1ecafa44db30579c8c457ac7a0f819e8b1dbc3e58308394fff5ff9ba7/murmurhash-0.28.0.tar.gz\n",
            "Collecting cymem<1.32,>=1.30 (from spacy)\n",
            "  Downloading https://files.pythonhosted.org/packages/f8/9e/273fbea507de99166c11cd0cb3fde1ac01b5bc724d9a407a2f927ede91a1/cymem-1.31.2.tar.gz\n",
            "Collecting preshed<2.0.0,>=1.0.0 (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/ac/7c17b1fd54b60972785b646d37da2826311cca70842c011c4ff84fbe95e0/preshed-1.0.0.tar.gz (89kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 19.7MB/s \n",
            "\u001b[?25hCollecting thinc<6.11.0,>=6.10.1 (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/fd/e9f36081e6f53699943381858848f3b4d759e0dd03c43b98807dde34c252/thinc-6.10.2.tar.gz (1.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.2MB 19.3MB/s \n",
            "\u001b[?25hCollecting plac<1.0.0,>=0.9.6 (from spacy)\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n",
            "Collecting pathlib (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/9b065a76b9af472437a0059f77e8f962fe350438b927cb80184c32f075eb/pathlib-1.0.1.tar.gz (49kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 16.8MB/s \n",
            "\u001b[?25hCollecting ujson>=1.35 (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/c4/79f3409bc710559015464e5f49b9879430d8f87498ecdc335899732e5377/ujson-1.35.tar.gz (192kB)\n",
            "\u001b[K    100% |████████████████████████████████| 194kB 18.5MB/s \n",
            "\u001b[?25hCollecting dill<0.3,>=0.2 (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/a0/19d4d31dee064fc553ae01263b5c55e7fb93daff03a69debbedee647c5a0/dill-0.2.7.1.tar.gz (64kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 20.9MB/s \n",
            "\u001b[?25hCollecting regex==2017.4.5 (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n",
            "\u001b[K    100% |████████████████████████████████| 604kB 21.8MB/s \n",
            "\u001b[?25hCollecting wrapt (from thinc<6.11.0,>=6.10.1->spacy)\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/47/66897906448185fcb77fc3c2b1bc20ed0ecca81a0f2f88eda3fc5a34fc3d/wrapt-1.10.11.tar.gz\n",
            "Collecting tqdm<5.0.0,>=4.10.0 (from thinc<6.11.0,>=6.10.1->spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/24/6ab1df969db228aed36a648a8959d1027099ce45fad67532b9673d533318/tqdm-4.23.4-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 19.9MB/s \n",
            "\u001b[?25hCollecting cytoolz<0.9,>=0.8 (from thinc<6.11.0,>=6.10.1->spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/e6/ccc124714dcc1bd511e64ddafb4d5d20ada2533b92e3173a4cf09e0d0831/cytoolz-0.8.2.tar.gz (386kB)\n",
            "\u001b[K    100% |████████████████████████████████| 389kB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (1.11.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (1.1.0)\n",
            "Collecting msgpack-python (from thinc<6.11.0,>=6.10.1->spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/20/6eca772d1a5830336f84aca1d8198e5a3f4715cd1c7fc36d3cc7f7185091/msgpack-python-0.5.6.tar.gz (138kB)\n",
            "\u001b[K    100% |████████████████████████████████| 143kB 22.1MB/s \n",
            "\u001b[?25hCollecting msgpack-numpy==0.4.1 (from thinc<6.11.0,>=6.10.1->spacy)\n",
            "  Downloading https://files.pythonhosted.org/packages/2e/43/393e30e2768b0357541ac95891f96b80ccc4d517e0dd2fa3042fc8926538/msgpack_numpy-0.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.9,>=0.8->thinc<6.11.0,>=6.10.1->spacy) (0.9.0)\n",
            "Building wheels for collected packages: spacy, murmurhash, cymem, preshed, thinc, pathlib, ujson, dill, regex, wrapt, cytoolz, msgpack-python\n",
            "  Running setup.py bdist_wheel for spacy ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/fb/00/28/75c85d5135e7d9a100639137d1847d41e914ed16c962d467e4\n",
            "  Running setup.py bdist_wheel for murmurhash ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/b8/94/a4/f69f8664cdc1098603df44771b7fec5fd1b3d8364cdd83f512\n",
            "  Running setup.py bdist_wheel for cymem ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/55/8d/4a/f6328252aa2aaec0b1cb906fd96a1566d77f0f67701071ad13\n",
            "  Running setup.py bdist_wheel for preshed ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/8f/85/06/2d132fb649a6bbcab22487e4147880a55b0dd0f4b18fdfd6b5\n",
            "  Running setup.py bdist_wheel for thinc ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/d8/5c/3e/9acf5d9974fb1c9e7b467563ea5429c9325f67306e93147961\n",
            "  Running setup.py bdist_wheel for pathlib ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/f9/b2/4a/68efdfe5093638a9918bd1bb734af625526e849487200aa171\n",
            "  Running setup.py bdist_wheel for ujson ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/28/77/e4/0311145b9c2e2f01470e744855131f9e34d6919687550f87d1\n",
            "  Running setup.py bdist_wheel for dill ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/99/c4/ed/1b64d2d5809e60d5a3685530432f6159d6a9959739facb61f2\n",
            "  Running setup.py bdist_wheel for regex ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n",
            "  Running setup.py bdist_wheel for wrapt ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/48/5d/04/22361a593e70d23b1f7746d932802efe1f0e523376a74f321e\n",
            "  Running setup.py bdist_wheel for cytoolz ... \u001b[?25l-\b \b\\\b \b|\b \b/"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/f8/b1/86/c92e4d36b690208fff8471711b85eaa6bc6d19860a86199a09\n",
            "  Running setup.py bdist_wheel for msgpack-python ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/d5/de/86/7fa56fda12511be47ea0808f3502bc879df4e63ab168ec0406\n",
            "Successfully built spacy murmurhash cymem preshed thinc pathlib ujson dill regex wrapt cytoolz msgpack-python\n",
            "Installing collected packages: murmurhash, cymem, preshed, wrapt, tqdm, cytoolz, plac, dill, pathlib, msgpack-python, msgpack-numpy, thinc, ujson, regex, spacy\n",
            "Successfully installed cymem-1.31.2 cytoolz-0.8.2 dill-0.2.7.1 msgpack-numpy-0.4.1 msgpack-python-0.5.6 murmurhash-0.28.0 pathlib-1.0.1 plac-0.9.6 preshed-1.0.0 regex-2017.4.5 spacy-2.0.11 thinc-6.10.2 tqdm-4.23.4 ujson-1.35 wrapt-1.10.11\n",
            "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
            "\u001b[K    89% |████████████████████████████▊   | 33.5MB 21.6MB/s eta 0:00:01"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 37.4MB 46.6MB/s \n",
            "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
            "  Running setup.py install for en-core-web-sm ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25hSuccessfully installed en-core-web-sm-2.0.0\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RvkWGmiTJD9-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# read after completion\n",
        "import spacy\n",
        "\n",
        "nlp=spacy.load(\"en\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GRQtneju7s_y",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nB4K9kv4JQCA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "0acf8860-3745-4433-b30c-def7b298c0a8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528259378218,
          "user_tz": -330,
          "elapsed": 3342,
          "user": {
            "displayName": "Hardik Ajmani",
            "photoUrl": "//lh3.googleusercontent.com/-vIpwTK-rcVg/AAAAAAAAAAI/AAAAAAAAFT4/chdlQWDf_D4/s50-c-k-no/photo.jpg",
            "userId": "117937753219477580457"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#load the dataset\n",
        "\n",
        "#uploading the dataset\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n",
        "#!wget -c https://raw.githubusercontent.com/crwong/cs224u-project/master/data/sentiment/training.1600000.processed.noemoticon.csv -O twitter.csv"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-06-06 04:29:36--  https://raw.githubusercontent.com/crwong/cs224u-project/master/data/sentiment/training.1600000.processed.noemoticon.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dlnSr2nSJXqz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "345fcbaa-b997-489f-9a8d-d8510f1af221",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528258959641,
          "user_tz": -330,
          "elapsed": 1065,
          "user": {
            "displayName": "Hardik Ajmani",
            "photoUrl": "//lh3.googleusercontent.com/-vIpwTK-rcVg/AAAAAAAAAAI/AAAAAAAAFT4/chdlQWDf_D4/s50-c-k-no/photo.jpg",
            "userId": "117937753219477580457"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#import the dataset\n",
        "\n",
        "train = pd.read_csv(\"twitter.csv\", encoding = \"latin - 1\")\n",
        "\n",
        "y = train[train.columns[0]]\n",
        "X = train[train.columns[5]]\n",
        "\n",
        "'''print(X)\n",
        "\n",
        "print(y)\n",
        "'''\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(X)\\n\\nprint(y)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "Jejty5VnJXE4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# split the data into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size = 0.2, random_state = 42)\n",
        "y_test = pd.get_dummies(y_test) #one hot encoding ke similar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n37Q_Pjt_NNs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#function to remove stopwords\n",
        "\n",
        "def stopwords(sent):\n",
        "  new = []\n",
        "  sent = nlp(sent)\n",
        "  for w in sent:\n",
        "    if(w.is_stop == False) & (w.pos_ != \"PUNCT\"):\n",
        "      new.append(w.string.strip())\n",
        "    c = \" \".join(str(x) for x in new)\n",
        "  return c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S_WicvzuALQi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# function to lemmatize the tweets\n",
        "def lemma(sent):\n",
        "  sent = nlp(sent)\n",
        "  str = \"\"\n",
        "  for w in sent:\n",
        "    str += \" \" + w.lemma_\n",
        "  return nlp(str)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f7sZhzjRA6zT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#loading the glove model (basically a step in vectorizing the corpus)\n",
        "\n",
        "def loadGloveModel(gloveFile):\n",
        "  print(\"Loading Glove Model\")\n",
        "  \n",
        "  f = open(gloveFile, 'r')\n",
        "  model = {}\n",
        "  for line in f:\n",
        "    splitLine = line.split()\n",
        "    word = splitLine[0]\n",
        "    embedding = [float(val) for val in splitLine[1:]]\n",
        "    model[word] = embedding\n",
        "  print(\"Done.\"),len(model), (\" words loaded!\")\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gmW3kgm3zQVV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I have downloaded the glove file on the virtual machine instead of doing it on the local machine. And later extracted that using zipfile"
      ]
    },
    {
      "metadata": {
        "id": "aRcdbJYwwmK0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "233cf196-09f1-43f6-80ae-9bf2510a48d5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528259067873,
          "user_tz": -330,
          "elapsed": 100949,
          "user": {
            "displayName": "Hardik Ajmani",
            "photoUrl": "//lh3.googleusercontent.com/-vIpwTK-rcVg/AAAAAAAAAAI/AAAAAAAAFT4/chdlQWDf_D4/s50-c-k-no/photo.jpg",
            "userId": "117937753219477580457"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "!wget \"http://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip\""
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-06-06 04:22:47--  http://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip [following]\n",
            "--2018-06-06 04:22:48--  https://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408741 (1.4G) [application/zip]\n",
            "Saving to: ‘glove.twitter.27B.zip’\n",
            "\n",
            "glove.twitter.27B.z  29%[====>               ] 427.98M  14.0MB/s    eta 81s    "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "glove.twitter.27B.z 100%[===================>]   1.42G  19.3MB/s    in 98s     \n",
            "\n",
            "2018-06-06 04:24:26 (14.8 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408741/1520408741]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RTI-ghtSvkcE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9cff0dd6-a68b-492e-fdeb-789a94094d92",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528259110370,
          "user_tz": -330,
          "elapsed": 42445,
          "user": {
            "displayName": "Hardik Ajmani",
            "photoUrl": "//lh3.googleusercontent.com/-vIpwTK-rcVg/AAAAAAAAAAI/AAAAAAAAFT4/chdlQWDf_D4/s50-c-k-no/photo.jpg",
            "userId": "117937753219477580457"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "file_name = \"glove.twitter.27B.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"Done\")\n",
        "  "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hMVu-n9LsgYX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bc11d483-c85b-44cc-e568-0499b8196598",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528259223104,
          "user_tz": -330,
          "elapsed": 112681,
          "user": {
            "displayName": "Hardik Ajmani",
            "photoUrl": "//lh3.googleusercontent.com/-vIpwTK-rcVg/AAAAAAAAAAI/AAAAAAAAFT4/chdlQWDf_D4/s50-c-k-no/photo.jpg",
            "userId": "117937753219477580457"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# save the glove model\n",
        "\n",
        "model = loadGloveModel(\"glove.twitter.27B.200d.txt\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Glove Model\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vciQ8dyUt_E-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#vectorizing the sentences\n",
        "def sent_vectorizer(sent, model):\n",
        "  \n",
        "  sent_vec = np.zeros(200)\n",
        "  numw = 0\n",
        "  for w in sent.split():\n",
        "    try:\n",
        "      \n",
        "      sent_vec = np.add(sent_vec, model[str(w)])\n",
        "      numw += 1\n",
        "    except:\n",
        "      pass\n",
        "    return sent_vec\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NDPbDi8Uus_8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#obtain a clean vector\n",
        "\n",
        "cleanvector = []\n",
        "for i in range(X_test.shape[0]):\n",
        "  document = X_test[i]\n",
        "  document = document.lower()\n",
        "  document = lemma(document)\n",
        "  document = str(document)\n",
        "  cleanvector.append(sent_vectorizer(document, model))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zH0XCwsR48zF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Getting the input and output in proper shape\n",
        "\n",
        "cleanvector = np.array(cleanvector)\n",
        "cleanvector = cleanvector.reshape(len(cleanvector), 200, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ag7Rc_I85Zen",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8faff088-6c5b-4bff-bfaf-c664ff145bfb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528259370660,
          "user_tz": -330,
          "elapsed": 1754,
          "user": {
            "displayName": "Hardik Ajmani",
            "photoUrl": "//lh3.googleusercontent.com/-vIpwTK-rcVg/AAAAAAAAAAI/AAAAAAAAFT4/chdlQWDf_D4/s50-c-k-no/photo.jpg",
            "userId": "117937753219477580457"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#tokenizing the sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=16000)\n",
        "tokenizer.fit_on_texts(X_test)\n",
        "sequences = tokenizer.texts_to_sequences(X_test)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens' %len(word_index))\n",
        "data = pad_sequences(sequences, maxlen = 15, padding = 'post')\n",
        "print(data.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9850 unique tokens\n",
            "(4000, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hdrzNpHJ8RRP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#reshape the data and prepair to train\n",
        "data = data.reshape(len(cleanvector), 15, 1)\n",
        "from sklearn.model_selection import train_test_split\n",
        "trainx, validx, trainy, validy = train_test_split(data, y_test, test_size = 0.3, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S5mJ7qF49i5r",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4238bd6-b6c8-4878-85aa-517b942aa581",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528259373397,
          "user_tz": -330,
          "elapsed": 1295,
          "user": {
            "displayName": "Hardik Ajmani",
            "photoUrl": "//lh3.googleusercontent.com/-vIpwTK-rcVg/AAAAAAAAAAI/AAAAAAAAFT4/chdlQWDf_D4/s50-c-k-no/photo.jpg",
            "userId": "117937753219477580457"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#calculate the number of words\n",
        "nb_words = len(tokenizer.word_index) + 1\n",
        "print(nb_words)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jz5D0S719z7t",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "232005b0-fb29-4b25-e827-d4abd3e93447",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528259374614,
          "user_tz": -330,
          "elapsed": 1031,
          "user": {
            "displayName": "Hardik Ajmani",
            "photoUrl": "//lh3.googleusercontent.com/-vIpwTK-rcVg/AAAAAAAAAAI/AAAAAAAAFT4/chdlQWDf_D4/s50-c-k-no/photo.jpg",
            "userId": "117937753219477580457"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#obtain the embedding matrix\n",
        "\n",
        "embedding_matrix = np.zeros((nb_words, 200))\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = model.get(word) #word ki vector representation mil rahi h\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis = 1) == 0))\n",
        "    "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Null word embeddings: 2801\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iE0XES0vXKBb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#converting the raininf data to numpy array\n",
        "\n",
        "trainy = np.array(trainy)\n",
        "validy = np.array(validy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qKZ4DyyiXY6p",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#building a simple rnn network\n",
        "def modelbuild():\n",
        "  model = Sequential()\n",
        "  model.add(keras.layers.InputLayer(input_shape=(15,1)))\n",
        "  keras.layers.embeddings.Embedding(nb_words, 15, weights = [embedding_matrix], input_length= 15, trainable = False)\n",
        "  \n",
        "  model.add(keras.layers.recurrent.SimpleRNN(units = 500, activation = 'relu', use_bias = True))\n",
        "  model.add(keras.layers.Dense(units = 1000, input_dim = 2000, activation = 'sigmoid'))\n",
        "  model.add(keras.layers.Dense(units = 500, input_dim = 1000, activation = 'relu'))\n",
        "  model.add(keras.layers.Dense(units = 2, input_dim = 500, activation = 'softmax'))\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YqUrBM9qZsJZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 6871
        },
        "outputId": "f7c714e6-07a4-4360-fdd3-26e3e3f19876",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528261394736,
          "user_tz": -330,
          "elapsed": 99161,
          "user": {
            "displayName": "Hardik Ajmani",
            "photoUrl": "//lh3.googleusercontent.com/-vIpwTK-rcVg/AAAAAAAAAAI/AAAAAAAAFT4/chdlQWDf_D4/s50-c-k-no/photo.jpg",
            "userId": "117937753219477580457"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#compiling the model\n",
        "final_model = modelbuild()\n",
        "final_model.fit(trainx, trainy, epochs = 200, batch_size = 120, validation_data = (validx, validy))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2800 samples, validate on 1200 samples\n",
            "Epoch 1/200\n",
            "2800/2800 [==============================] - 1s 317us/step - loss: 0.9008 - acc: 0.5150 - val_loss: 0.7227 - val_acc: 0.4817\n",
            "Epoch 2/200\n",
            "2800/2800 [==============================] - 0s 164us/step - loss: 0.7118 - acc: 0.5018 - val_loss: 0.6925 - val_acc: 0.5200\n",
            "Epoch 3/200\n",
            "2800/2800 [==============================] - 0s 161us/step - loss: 0.7302 - acc: 0.5064 - val_loss: 0.7013 - val_acc: 0.5183\n",
            "Epoch 4/200\n",
            "2800/2800 [==============================] - 0s 175us/step - loss: 0.7206 - acc: 0.5079 - val_loss: 0.6933 - val_acc: 0.5183\n",
            "Epoch 5/200\n",
            "2800/2800 [==============================] - 0s 169us/step - loss: 0.7094 - acc: 0.5004 - val_loss: 0.6992 - val_acc: 0.5183\n",
            "Epoch 6/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.7017 - acc: 0.4929 - val_loss: 0.7009 - val_acc: 0.5183\n",
            "Epoch 7/200\n",
            "2800/2800 [==============================] - 0s 174us/step - loss: 0.6966 - acc: 0.5111 - val_loss: 0.7323 - val_acc: 0.4817\n",
            "Epoch 8/200\n",
            "2800/2800 [==============================] - 0s 173us/step - loss: 0.7163 - acc: 0.5029 - val_loss: 0.7021 - val_acc: 0.4817\n",
            "Epoch 9/200\n",
            "2800/2800 [==============================] - 0s 173us/step - loss: 0.7309 - acc: 0.4979 - val_loss: 0.7025 - val_acc: 0.4817\n",
            "Epoch 10/200\n",
            "2800/2800 [==============================] - 0s 173us/step - loss: 0.7166 - acc: 0.5157 - val_loss: 0.7445 - val_acc: 0.4817\n",
            "Epoch 11/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.7049 - acc: 0.4943 - val_loss: 0.7065 - val_acc: 0.5183\n",
            "Epoch 12/200\n",
            "2040/2800 [====================>.........] - ETA: 0s - loss: 0.7082 - acc: 0.5093"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2800/2800 [==============================] - 0s 169us/step - loss: 0.7071 - acc: 0.5086 - val_loss: 0.6928 - val_acc: 0.5183\n",
            "Epoch 13/200\n",
            "2800/2800 [==============================] - 0s 169us/step - loss: 0.6986 - acc: 0.4943 - val_loss: 0.6925 - val_acc: 0.5183\n",
            "Epoch 14/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.7015 - acc: 0.5007 - val_loss: 0.7000 - val_acc: 0.4817\n",
            "Epoch 15/200\n",
            "2800/2800 [==============================] - 0s 167us/step - loss: 0.6980 - acc: 0.5029 - val_loss: 0.6925 - val_acc: 0.5183\n",
            "Epoch 16/200\n",
            "2800/2800 [==============================] - 0s 167us/step - loss: 0.6995 - acc: 0.5114 - val_loss: 0.7000 - val_acc: 0.4817\n",
            "Epoch 17/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.7032 - acc: 0.4936 - val_loss: 0.6925 - val_acc: 0.5183\n",
            "Epoch 18/200\n",
            "2800/2800 [==============================] - 0s 173us/step - loss: 0.6976 - acc: 0.4950 - val_loss: 0.6953 - val_acc: 0.4817\n",
            "Epoch 19/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.7013 - acc: 0.5093 - val_loss: 0.7208 - val_acc: 0.5183\n",
            "Epoch 20/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.7066 - acc: 0.5086 - val_loss: 0.6984 - val_acc: 0.5183\n",
            "Epoch 21/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.7004 - acc: 0.4964 - val_loss: 0.6963 - val_acc: 0.5183\n",
            "Epoch 22/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6983 - acc: 0.5036 - val_loss: 0.7004 - val_acc: 0.5183\n",
            "Epoch 23/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6985 - acc: 0.4893 - val_loss: 0.6933 - val_acc: 0.5183\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 24/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6970 - acc: 0.5029 - val_loss: 0.6931 - val_acc: 0.5183\n",
            "Epoch 25/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6955 - acc: 0.4893 - val_loss: 0.6936 - val_acc: 0.4817\n",
            "Epoch 26/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.7080 - acc: 0.5014 - val_loss: 0.6934 - val_acc: 0.5183\n",
            "Epoch 27/200\n",
            "2800/2800 [==============================] - 0s 174us/step - loss: 0.7087 - acc: 0.5093 - val_loss: 0.6925 - val_acc: 0.5183\n",
            "Epoch 28/200\n",
            "2800/2800 [==============================] - 0s 177us/step - loss: 0.6945 - acc: 0.5071 - val_loss: 0.6975 - val_acc: 0.5183\n",
            "Epoch 29/200\n",
            "2800/2800 [==============================] - 0s 177us/step - loss: 0.6974 - acc: 0.4911 - val_loss: 0.7015 - val_acc: 0.4817\n",
            "Epoch 30/200\n",
            "2800/2800 [==============================] - 0s 176us/step - loss: 0.6964 - acc: 0.5050 - val_loss: 0.6925 - val_acc: 0.5183\n",
            "Epoch 31/200\n",
            "2800/2800 [==============================] - 0s 169us/step - loss: 0.6945 - acc: 0.4943 - val_loss: 0.7022 - val_acc: 0.4817\n",
            "Epoch 32/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.6955 - acc: 0.5007 - val_loss: 0.6971 - val_acc: 0.5183\n",
            "Epoch 33/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6959 - acc: 0.4971 - val_loss: 0.6941 - val_acc: 0.4817\n",
            "Epoch 34/200\n",
            "2800/2800 [==============================] - 0s 173us/step - loss: 0.6939 - acc: 0.4971 - val_loss: 0.6925 - val_acc: 0.5183\n",
            "Epoch 35/200\n",
            "2640/2800 [===========================>..] - ETA: 0s - loss: 0.6943 - acc: 0.4951"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2800/2800 [==============================] - 0s 171us/step - loss: 0.6945 - acc: 0.4943 - val_loss: 0.6985 - val_acc: 0.4817\n",
            "Epoch 36/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6941 - acc: 0.5129 - val_loss: 0.7019 - val_acc: 0.4817\n",
            "Epoch 37/200\n",
            "2800/2800 [==============================] - 0s 169us/step - loss: 0.6939 - acc: 0.5036 - val_loss: 0.6926 - val_acc: 0.5183\n",
            "Epoch 38/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.6949 - acc: 0.5100 - val_loss: 0.6925 - val_acc: 0.5183\n",
            "Epoch 39/200\n",
            "2800/2800 [==============================] - 0s 169us/step - loss: 0.6946 - acc: 0.5121 - val_loss: 0.6943 - val_acc: 0.5183\n",
            "Epoch 40/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6943 - acc: 0.5000 - val_loss: 0.6926 - val_acc: 0.5183\n",
            "Epoch 41/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.6946 - acc: 0.4971 - val_loss: 0.6966 - val_acc: 0.4817\n",
            "Epoch 42/200\n",
            "2800/2800 [==============================] - 0s 169us/step - loss: 0.6972 - acc: 0.4986 - val_loss: 0.6953 - val_acc: 0.4817\n",
            "Epoch 43/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6934 - acc: 0.5150 - val_loss: 0.6925 - val_acc: 0.5183\n",
            "Epoch 44/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.6938 - acc: 0.4993 - val_loss: 0.6976 - val_acc: 0.4817\n",
            "Epoch 45/200\n",
            "2800/2800 [==============================] - 0s 174us/step - loss: 0.6945 - acc: 0.4893 - val_loss: 0.6925 - val_acc: 0.5183\n",
            "Epoch 46/200\n",
            "1200/2800 [===========>..................] - ETA: 0s - loss: 0.6930 - acc: 0.5142"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6944 - acc: 0.5000 - val_loss: 0.6973 - val_acc: 0.4817\n",
            "Epoch 47/200\n",
            "2800/2800 [==============================] - 0s 173us/step - loss: 0.6967 - acc: 0.4829 - val_loss: 0.6925 - val_acc: 0.5183\n",
            "Epoch 48/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6952 - acc: 0.5143 - val_loss: 0.6938 - val_acc: 0.5183\n",
            "Epoch 49/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6947 - acc: 0.4993 - val_loss: 0.6926 - val_acc: 0.5183\n",
            "Epoch 50/200\n",
            "2800/2800 [==============================] - 0s 173us/step - loss: 0.6953 - acc: 0.4914 - val_loss: 0.6925 - val_acc: 0.5183\n",
            "Epoch 51/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6952 - acc: 0.4836 - val_loss: 0.6926 - val_acc: 0.5183\n",
            "Epoch 52/200\n",
            "2800/2800 [==============================] - 0s 174us/step - loss: 0.6952 - acc: 0.4982 - val_loss: 0.6944 - val_acc: 0.4817\n",
            "Epoch 53/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.6940 - acc: 0.5007 - val_loss: 0.6943 - val_acc: 0.4817\n",
            "Epoch 54/200\n",
            "2800/2800 [==============================] - 0s 166us/step - loss: 0.6941 - acc: 0.5036 - val_loss: 0.6961 - val_acc: 0.4817\n",
            "Epoch 55/200\n",
            "2800/2800 [==============================] - 0s 174us/step - loss: 0.6949 - acc: 0.4736 - val_loss: 0.6942 - val_acc: 0.4817\n",
            "Epoch 56/200\n",
            "2800/2800 [==============================] - 0s 173us/step - loss: 0.6935 - acc: 0.4900 - val_loss: 0.6931 - val_acc: 0.5183\n",
            "Epoch 57/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.6934 - acc: 0.4993 - val_loss: 0.6940 - val_acc: 0.4817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 58/200\n",
            "2800/2800 [==============================] - 0s 169us/step - loss: 0.6934 - acc: 0.4900 - val_loss: 0.6937 - val_acc: 0.4817\n",
            "Epoch 59/200\n",
            "2800/2800 [==============================] - 1s 179us/step - loss: 0.6934 - acc: 0.5014 - val_loss: 0.6935 - val_acc: 0.4817\n",
            "Epoch 60/200\n",
            "2800/2800 [==============================] - 1s 181us/step - loss: 0.6933 - acc: 0.4950 - val_loss: 0.6935 - val_acc: 0.4817\n",
            "Epoch 61/200\n",
            "2800/2800 [==============================] - 1s 179us/step - loss: 0.6933 - acc: 0.5014 - val_loss: 0.6929 - val_acc: 0.5183\n",
            "Epoch 62/200\n",
            "2800/2800 [==============================] - 0s 178us/step - loss: 0.6941 - acc: 0.4986 - val_loss: 0.6928 - val_acc: 0.5183\n",
            "Epoch 63/200\n",
            "2800/2800 [==============================] - 0s 175us/step - loss: 0.6933 - acc: 0.4979 - val_loss: 0.6935 - val_acc: 0.4817\n",
            "Epoch 64/200\n",
            "2800/2800 [==============================] - 0s 173us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6934 - val_acc: 0.4817\n",
            "Epoch 65/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6934 - val_acc: 0.4817\n",
            "Epoch 66/200\n",
            "2800/2800 [==============================] - 0s 169us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 67/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 68/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 69/200\n",
            "2280/2800 [=======================>......] - ETA: 0s - loss: 0.6932 - acc: 0.5031"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 70/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6932 - acc: 0.5018 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 71/200\n",
            "2800/2800 [==============================] - 0s 175us/step - loss: 0.6932 - acc: 0.5018 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 72/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.6931 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 73/200\n",
            "2800/2800 [==============================] - 0s 168us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 74/200\n",
            "2800/2800 [==============================] - 0s 173us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6934 - val_acc: 0.4817\n",
            "Epoch 75/200\n",
            "2800/2800 [==============================] - 0s 174us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 76/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 77/200\n",
            "2800/2800 [==============================] - 0s 174us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 78/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 79/200\n",
            "2800/2800 [==============================] - 0s 173us/step - loss: 0.6932 - acc: 0.4954 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 80/200\n",
            "2800/2800 [==============================] - 0s 166us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 81/200\n",
            " 480/2800 [====>.........................] - ETA: 0s - loss: 0.6933 - acc: 0.4688"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 82/200\n",
            "2800/2800 [==============================] - 1s 179us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 83/200\n",
            "2800/2800 [==============================] - 0s 179us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 84/200\n",
            "2800/2800 [==============================] - 0s 173us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 85/200\n",
            "2800/2800 [==============================] - 0s 176us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 86/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 87/200\n",
            "2800/2800 [==============================] - 0s 174us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 88/200\n",
            "2800/2800 [==============================] - 0s 166us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 89/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6931 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 90/200\n",
            "2800/2800 [==============================] - 0s 177us/step - loss: 0.6932 - acc: 0.4879 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 91/200\n",
            "2800/2800 [==============================] - 0s 174us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 92/200\n",
            "2800/2800 [==============================] - 0s 174us/step - loss: 0.6931 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 93/200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2800/2800 [==============================] - 0s 164us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 94/200\n",
            "2800/2800 [==============================] - 0s 168us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 95/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.6932 - acc: 0.4864 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 96/200\n",
            "2800/2800 [==============================] - 0s 169us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 97/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6931 - acc: 0.5018 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 98/200\n",
            "2800/2800 [==============================] - 0s 169us/step - loss: 0.6932 - acc: 0.5018 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 99/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.6932 - acc: 0.4900 - val_loss: 0.6931 - val_acc: 0.5183\n",
            "Epoch 100/200\n",
            "2800/2800 [==============================] - 0s 174us/step - loss: 0.6932 - acc: 0.5007 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 101/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.6931 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 102/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 103/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 104/200\n",
            "2640/2800 [===========================>..] - ETA: 0s - loss: 0.6932 - acc: 0.5015"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2800/2800 [==============================] - 0s 170us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 105/200\n",
            "2800/2800 [==============================] - 0s 166us/step - loss: 0.6931 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 106/200\n",
            "2800/2800 [==============================] - 0s 168us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 107/200\n",
            "2800/2800 [==============================] - 0s 174us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 108/200\n",
            "2800/2800 [==============================] - 0s 174us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 109/200\n",
            "2800/2800 [==============================] - 0s 175us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 110/200\n",
            "2800/2800 [==============================] - 0s 169us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 111/200\n",
            "2800/2800 [==============================] - 0s 175us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 112/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 113/200\n",
            "2800/2800 [==============================] - 0s 174us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 114/200\n",
            "2800/2800 [==============================] - 0s 175us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 115/200\n",
            "2280/2800 [=======================>......] - ETA: 0s - loss: 0.6932 - acc: 0.5009"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6934 - val_acc: 0.4817\n",
            "Epoch 116/200\n",
            "2800/2800 [==============================] - 0s 178us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 117/200\n",
            "2800/2800 [==============================] - 0s 174us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6934 - val_acc: 0.4817\n",
            "Epoch 118/200\n",
            "2800/2800 [==============================] - 0s 175us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6934 - val_acc: 0.4817\n",
            "Epoch 119/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6934 - val_acc: 0.4817\n",
            "Epoch 120/200\n",
            "2800/2800 [==============================] - 0s 174us/step - loss: 0.6931 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 121/200\n",
            "2800/2800 [==============================] - 1s 180us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 122/200\n",
            "2800/2800 [==============================] - 0s 176us/step - loss: 0.6931 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 123/200\n",
            "2800/2800 [==============================] - 0s 176us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 124/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 125/200\n",
            "2800/2800 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 126/200\n",
            "2800/2800 [==============================] - 0s 164us/step - loss: 0.6932 - acc: 0.5018 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 127/200\n",
            " 120/2800 [>.............................] - ETA: 0s - loss: 0.6930 - acc: 0.5500"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2800/2800 [==============================] - 0s 169us/step - loss: 0.6931 - acc: 0.5018 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 128/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 129/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6931 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 130/200\n",
            "2800/2800 [==============================] - 0s 173us/step - loss: 0.6932 - acc: 0.4864 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 131/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 132/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 133/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 134/200\n",
            "2800/2800 [==============================] - 0s 169us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 135/200\n",
            "2800/2800 [==============================] - 0s 169us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 136/200\n",
            "2800/2800 [==============================] - 0s 173us/step - loss: 0.6932 - acc: 0.4836 - val_loss: 0.6931 - val_acc: 0.5183\n",
            "Epoch 137/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6932 - acc: 0.4943 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 138/200\n",
            "2800/2800 [==============================] - 0s 177us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 139/200\n",
            "2800/2800 [==============================] - 1s 182us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 140/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6932 - acc: 0.4821 - val_loss: 0.6931 - val_acc: 0.5183\n",
            "Epoch 141/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.6932 - acc: 0.4900 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 142/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6932 - acc: 0.4829 - val_loss: 0.6931 - val_acc: 0.5183\n",
            "Epoch 143/200\n",
            "2800/2800 [==============================] - 0s 173us/step - loss: 0.6932 - acc: 0.4950 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 144/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 145/200\n",
            "2800/2800 [==============================] - 0s 173us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 146/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6931 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 147/200\n",
            "2800/2800 [==============================] - 0s 175us/step - loss: 0.6931 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 148/200\n",
            "2800/2800 [==============================] - 0s 168us/step - loss: 0.6932 - acc: 0.4914 - val_loss: 0.6931 - val_acc: 0.5183\n",
            "Epoch 149/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6932 - acc: 0.4943 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 150/200\n",
            "2800/2800 [==============================] - 0s 169us/step - loss: 0.6932 - acc: 0.4943 - val_loss: 0.6931 - val_acc: 0.5183\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 151/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6932 - acc: 0.4986 - val_loss: 0.6931 - val_acc: 0.5183\n",
            "Epoch 152/200\n",
            "2800/2800 [==============================] - 0s 175us/step - loss: 0.6932 - acc: 0.4957 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 153/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6932 - acc: 0.4957 - val_loss: 0.6931 - val_acc: 0.5183\n",
            "Epoch 154/200\n",
            "2800/2800 [==============================] - 0s 173us/step - loss: 0.6931 - acc: 0.5036 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 155/200\n",
            "2800/2800 [==============================] - 0s 173us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 156/200\n",
            "2800/2800 [==============================] - 0s 174us/step - loss: 0.6932 - acc: 0.4907 - val_loss: 0.6931 - val_acc: 0.5183\n",
            "Epoch 157/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6932 - acc: 0.4957 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 158/200\n",
            "2800/2800 [==============================] - 0s 177us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 159/200\n",
            "2800/2800 [==============================] - 1s 180us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 160/200\n",
            "2800/2800 [==============================] - 1s 185us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 161/200\n",
            "2800/2800 [==============================] - 0s 177us/step - loss: 0.6932 - acc: 0.4764 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 162/200\n",
            "2800/2800 [==============================] - 0s 178us/step - loss: 0.6931 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 163/200\n",
            " 480/2800 [====>.........................] - ETA: 0s - loss: 0.6928 - acc: 0.5333"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2800/2800 [==============================] - 0s 177us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 164/200\n",
            "2800/2800 [==============================] - 1s 181us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6935 - val_acc: 0.4817\n",
            "Epoch 165/200\n",
            "2800/2800 [==============================] - 0s 169us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6934 - val_acc: 0.4817\n",
            "Epoch 166/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 167/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6934 - val_acc: 0.4817\n",
            "Epoch 168/200\n",
            "2800/2800 [==============================] - 0s 174us/step - loss: 0.6931 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 169/200\n",
            "2800/2800 [==============================] - 1s 180us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 170/200\n",
            "2800/2800 [==============================] - 0s 178us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 171/200\n",
            "2800/2800 [==============================] - 1s 181us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 172/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 173/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 174/200\n",
            "2800/2800 [==============================] - 0s 169us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 175/200\n",
            " 120/2800 [>.............................] - ETA: 0s - loss: 0.6930 - acc: 0.5333"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2800/2800 [==============================] - 0s 166us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 176/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 177/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 178/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 179/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6931 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 180/200\n",
            "2800/2800 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4679 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 181/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 182/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 183/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6931 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 184/200\n",
            "2800/2800 [==============================] - 0s 176us/step - loss: 0.6932 - acc: 0.4961 - val_loss: 0.6931 - val_acc: 0.5183\n",
            "Epoch 185/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6932 - acc: 0.4950 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 186/200\n",
            "2800/2800 [==============================] - 0s 169us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 187/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.6932 - acc: 0.4850 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 188/200\n",
            "2800/2800 [==============================] - 0s 170us/step - loss: 0.6932 - acc: 0.4914 - val_loss: 0.6931 - val_acc: 0.5183\n",
            "Epoch 189/200\n",
            "2800/2800 [==============================] - 0s 173us/step - loss: 0.6932 - acc: 0.4936 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 190/200\n",
            "2800/2800 [==============================] - 0s 169us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 191/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 192/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4817\n",
            "Epoch 193/200\n",
            "2800/2800 [==============================] - 0s 171us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 194/200\n",
            "2800/2800 [==============================] - 0s 173us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 195/200\n",
            "2800/2800 [==============================] - 0s 172us/step - loss: 0.6931 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 196/200\n",
            "2800/2800 [==============================] - 1s 182us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 197/200\n",
            "2800/2800 [==============================] - 0s 174us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n",
            "Epoch 198/200\n",
            "2640/2800 [===========================>..] - ETA: 0s - loss: 0.6931 - acc: 0.5023"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2800/2800 [==============================] - 0s 173us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6934 - val_acc: 0.4817\n",
            "Epoch 199/200\n",
            "2800/2800 [==============================] - 1s 179us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6934 - val_acc: 0.4817\n",
            "Epoch 200/200\n",
            "2800/2800 [==============================] - 0s 178us/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa81940bb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "BpDWQtf4bvhR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fed39baa-885c-4525-ee46-f47b8fb14cd0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528261400766,
          "user_tz": -330,
          "elapsed": 1133,
          "user": {
            "displayName": "Hardik Ajmani",
            "photoUrl": "//lh3.googleusercontent.com/-vIpwTK-rcVg/AAAAAAAAAAI/AAAAAAAAFT4/chdlQWDf_D4/s50-c-k-no/photo.jpg",
            "userId": "117937753219477580457"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#getting the accuracy on validation set on last epoch\n",
        "\n",
        "loss, acc = final_model.evaluate(validx, validy, verbose = 0)\n",
        "print(\"Accuracy: \" + str(acc * 100))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 48.16666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}